{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1 for CS 247 : Advanced Data Mining Learning\n",
    "\n",
    "### Due: 11:59 pm 04/07\n",
    "\n",
    "\n",
    "__Name__: Shen Teng\n",
    "\n",
    "__UID__: 104758168"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 Multinomial Naive Bayes Optimization\n",
    "\n",
    "For multinomial naive Bayes model, prove the MLE estimator β for what is stated in Slide 21."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This  is the log likelihood function\n",
    "$$\n",
    "\\begin{align}log{L{(\\Theta)}}&=\\sum_d{(\\sum_n{x_{dn} log{\\beta_{y_{d}n}}}+log{\\pi_{y_d}}}) \\\\\\end{align}\n",
    "$$\n",
    "Let us apply Lagrange multiplier on it\n",
    "$$\n",
    "\\begin{align}J &= \\sum_d{\\sum_n{x_{dn} log{\\beta_{y_dn}}}}+\\lambda_j(\\sum_n{\\beta_{jn}-1}) \\\\& = \\sum_d{\\sum_n{\\sum_j{\\mathbb{1} (y_d == j) x_{dn} log{\\beta_{jn}}}}+\\lambda_j(\\sum_n{\\beta_{jn}-1})} \\\\\\end{align}\n",
    "$$\n",
    "Take derivative on $ {\\beta_{jn}} $ then set it equal to 0:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J} {\\partial {\\beta_{jn}}} = \\sum_d{\\frac {x_{dn}}{\\beta_{jn}}} + \\lambda_j &= 0 \\space where ( j==y_d )\\\\\n",
    "\\sum_d{x_{dn}+\\beta_{jn}\\lambda_j}&=0\n",
    "\\end{align}\n",
    "$$\n",
    "Sum over j n terms:\n",
    "$$\n",
    "\\begin{align}\n",
    "0 &= \\sum_n{\\sum_d{x_dn}}+\\sum_n{\\beta_{jn}\\lambda_j}  \\\\\n",
    "\\lambda_j &= -\\frac{\\sum_n{\\sum_d{x_{dn}}}}{\\sum_n{\\beta_{jn}}}\\\\\n",
    "\\lambda_j &= -{\\sum_n{\\sum_d{x_{dn}}}}\n",
    "\\end{align}\n",
    "$$\n",
    "Plug it back to $\\hat{\\beta_{jn}}$:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sum_d{x_dn}+\\hat{\\beta_{jn}} \\lambda_j = 0 \\\\\n",
    "\\hat{\\beta_{jn}} = \\frac{- \\sum_{d：y_d == j}{x_{dn}}}{\\lambda_j} \\\\\n",
    "\\hat{\\beta_{jn}} = \\frac{- \\sum_{d：y_d == j}{x_{dn}}}{\\sum_{d:y_d==j}{\\sum_{n'}{x_{dn'}}}}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2:  Multinomial Naive Bayes Implementation\n",
    "\n",
    "\n",
    "In this problem, we'd like you to implement naive bayes, and apply it on a real-world sentiment classification dataset. \n",
    "\n",
    "1. We've provided a general framework \"My_MultinomialNB\" below, please fill ''TODO'' slots. More specifically, you should implement the ***fit***, ***predict_proba_without_log*** and ***predict_log_proba_with_log*** functions. \n",
    "\n",
    "    For function ***fit***, given a training dataset with feature ***X*** and label ***y***, we'd like you to calculate ***beta*** and ***pi*** with a smoothing parameter ***alpha*** (laplace smoothing). \n",
    "\n",
    "    For ***predict_proba_without_log***, given a test dataset with feature X, we'd like you to calculate the predicted probability of each data point using what we've learned in class.\n",
    "\n",
    "    For ***predict_log_proba_with_log***, given a test dataset with feature ***X***, we'd like you to calculate the log probability of each data point, using ***log_beta*** and ***log_pi***. With this function, we can also get probability using ***predict_proba_with_log***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_MultinomialNB():\n",
    "    \"\"\"\n",
    "    Multinomial Naive Bayes (MultinomialNB)\n",
    "    ==========  \n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha : float, optional (default=1.0)\n",
    "        Additive (Laplace/Lidstone) smoothing parameter\n",
    "        (0 for no smoothing).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha=1):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.class_indicator = {}\n",
    "        for i, c in enumerate(np.unique(y)):\n",
    "            self.class_indicator[c] = i\n",
    "        self.n_class = len(self.class_indicator)\n",
    "        self.n_feats = np.shape(X)[1]\n",
    "        \n",
    "        self.beta    = np.zeros((self.n_class, self.n_feats))\n",
    "        self.pi      = np.zeros((self.n_class))\n",
    "        '''\n",
    "            TODO: Calculate self.beta and self.pi\n",
    "        '''\n",
    "       \n",
    "        # calculate BETAs\n",
    "        for idx_doc in range(X.shape[0]):\n",
    "            self.beta[y[idx_doc]] += X[idx_doc] #calculate the numerator\n",
    "        self.beta += self.alpha #add smoothing factor to each element\n",
    "        \n",
    "        #divide by the sum of each category\n",
    "        for idx_doc in range(X.shape[0]):\n",
    "            self.beta[y[idx_doc]] = self.beta[y[idx_doc]]/sum(self.beta[y[idx_doc]]) \n",
    "         \n",
    "        \n",
    "        #calculate PIs\n",
    "        for label in y:\n",
    "            self.pi[self.class_indicator[label]]+=1\n",
    "        self.pi = self.pi / len(y)\n",
    "        \n",
    "            \n",
    "        self.log_beta = np.log(self.beta)\n",
    "        self.log_pi   = np.log(self.pi)\n",
    "        \n",
    "    def predict(self, X, with_log = True):\n",
    "        if with_log:\n",
    "            probability = self.predict_proba_with_log(X)\n",
    "        else:\n",
    "            probability = self.predict_proba_without_log(X)\n",
    "        return np.argmax(probability, axis=1)    \n",
    "    \n",
    "    def predict_proba_without_log(self, X):\n",
    "        prob = np.zeros((len(X), self.n_class))\n",
    "        '''\n",
    "            TODO: Calculate probability of which class each data belongs to, using self.beta and self.pi\n",
    "        '''\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(self.n_class):\n",
    "                prob[i][j] = np.prod(self.beta[j] ** X[i]) * self.pi[j]\n",
    "        return prob\n",
    "    \n",
    "    def predict_proba_with_log(self, X):\n",
    "        log_prob = self.predict_log_proba_with_log(X)\n",
    "        return np.exp(log_prob - np.max(log_prob, axis=1).reshape(-1, 1))\n",
    "    \n",
    "    def predict_log_proba_with_log(self, X):\n",
    "        log_prob = np.zeros((len(X), self.n_class))\n",
    "        '''\n",
    "            TODO: Calculate log-probability of which class each data belongs to, using self.log_beta and self.log_pi\n",
    "        '''\n",
    "        log_prob = X.dot(self.log_beta.T)+ self.log_pi\n",
    "        return log_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Try your Multinomial Naive Bayes Implementation on a real-world dataset and compare with the model implemented in *sklearn*.\n",
    "   \n",
    "    We've already provided the data processing code below, which will help you download 20newsgroups dataset and extract word frequency feature for each document. We also provide the code for training and predict the probability of test data, using *sklearn* implementation.\n",
    "    \n",
    "    Now, try to train the model you implement, and calculate the probability of test data using ***predict_proba_without_log*** and ***predict_log_proba_with_log***. Compare the result with what \"e got by *sklearn* model, are they same or not? If they are different, please try to explain the reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anwser**: For predict_proba_without_log, sklearn result is different from my result. I think it is because the numbers are really small. Multiplying them several times makes them really close to zero(due to the nature of the float representation). \n",
    "\n",
    "But for predict_log_proba_with_log, they are very similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['alt.atheism', 'soc.religion.christian',  'comp.graphics', 'sci.med']\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
    "twenty_test  = fetch_20newsgroups(subset='test',  categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "count_vect = CountVectorizer().fit(twenty_train['data'] + twenty_test['data'])\n",
    "X_train_feature = count_vect.transform(twenty_train['data']).toarray()\n",
    "X_test_feature  = count_vect.transform(twenty_test['data']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_feature, twenty_train.target)\n",
    "pred_proba = clf.predict_proba(X_test_feature)\n",
    "pred = clf.predict(X_test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = My_MultinomialNB()\n",
    "'''\n",
    "    TODO: Train your model, and then get the probability result using \"predict_proba_without_log\" and \"predict_proba_with_log\"\n",
    "'''\n",
    "import numpy as np\n",
    "my_clf.fit(X_train_feature, twenty_train.target)\n",
    "my_pred_proba = my_clf.predict_proba_without_log(X_test_feature)\n",
    "my_pred_proba_log = my_clf.predict_log_proba_with_log(X_test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.38061375e-017, 2.59205885e-025, 1.00000000e+000,\n",
       "        1.20310868e-021],\n",
       "       [3.37631010e-133, 2.75179173e-163, 1.00000000e+000,\n",
       "        6.43247419e-138],\n",
       "       [2.58927085e-004, 4.94679710e-033, 1.00000000e+000,\n",
       "        5.03250023e-016],\n",
       "       ...,\n",
       "       [1.01604625e-041, 8.37145506e-065, 1.00000000e+000,\n",
       "        1.01984918e-043],\n",
       "       [2.15010601e-014, 6.26812388e-014, 1.00000000e+000,\n",
       "        5.05934556e-017],\n",
       "       [9.27230806e-020, 1.00000000e+000, 3.44019677e-020,\n",
       "        4.40514843e-029]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compare probability\n",
    "my_pred_proba = my_clf.predict_proba_with_log(X_test_feature)\n",
    "my_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.38061375e-017, 2.59205885e-025, 1.00000000e+000,\n",
       "        1.20310868e-021],\n",
       "       [3.37631010e-133, 2.75179173e-163, 1.00000000e+000,\n",
       "        6.43247419e-138],\n",
       "       [2.58860059e-004, 4.94551658e-033, 9.99741140e-001,\n",
       "        5.03119752e-016],\n",
       "       ...,\n",
       "       [1.01604625e-041, 8.37145507e-065, 1.00000000e+000,\n",
       "        1.01984918e-043],\n",
       "       [2.15010601e-014, 6.26812388e-014, 1.00000000e+000,\n",
       "        5.05934556e-017],\n",
       "       [9.27230806e-020, 1.00000000e+000, 3.44019677e-020,\n",
       "        4.40514843e-029]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((pred-my_clf.predict(X_test_feature))) #show my prediction is the same as the prediction of sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Now, provide the evaluation result of your model, using accuracy as evaluation metric. \n",
    "    Next, choose different laplacian smoothing parameter ***alpha***, including (0, 0.001, 0.01, 0.1, 1, 10, 100, 1000). Plot the accuracy curve with different ***alpha*** using *matplotlib* package or *seaborn* package. \n",
    "    \n",
    "3. What is the best ***alpha***? Please explain why when ***alpha*** = 0 and ***alpha*** = 1000, the performance is relatively worse than the best case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anwser**: \n",
    "Best $alpha$ is 0.01.\n",
    "\n",
    "For $alpha$ = 0, some $\\beta_{ij}$ can be zero since some words are not presented in some categories. This kind of words will make the prediction probablity equal to 0 even though the rest of the wors are be very relevant.\n",
    "\n",
    "For $alpha$ = 1000, it make all words have similar impact since it is too big as a smoothing factor comparing to the input size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-d8e9309368c1>:44: RuntimeWarning: divide by zero encountered in log\n",
      "  self.log_beta = np.log(self.beta)\n"
     ]
    }
   ],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    '''\n",
    "        TODO: Implement accuracy metric\n",
    "    '''\n",
    "    return 1-(np.count_nonzero(y_true-y_pred))/len(y_true)\n",
    "\n",
    "accs = []\n",
    "for alpha in [0, 0.001, 0.1, 1, 10, 100, 1000, 10000]:\n",
    "    '''\n",
    "        TODO: Train the model with different alpha, and get corresponding a\n",
    "    '''\n",
    "    my_clf = My_MultinomialNB(alpha)\n",
    "    my_clf.fit(X_train_feature, twenty_train.target)\n",
    "    pred = my_clf.predict(X_test_feature)\n",
    "    accs.append(accuracy(twenty_test['target'],pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(accs)\n",
    "plt.xticks(np.arange(8), [0, 0.001, 0.01, 0.1, 1, 10, 100, 1000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2123834886817576,\n",
       " 0.9447403462050599,\n",
       " 0.9507323568575233,\n",
       " 0.9347536617842876,\n",
       " 0.7609853528628495,\n",
       " 0.3588548601864181,\n",
       " 0.27230359520639147,\n",
       " 0.26564580559254325]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
